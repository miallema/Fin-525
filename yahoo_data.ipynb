{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_CLEAN_DIR = os.path.join(CWD, 'data/Clean/')\n",
    "\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2017-01-01'\n",
    "\n",
    "stocks = ['ABBN','CSGN','NESN','NOVN']\n",
    "stocks_yahoo = ['ABBN.VX','CSGN.VX','NESN.VX','NOVN.VX']\n",
    "stocks_pred = ['ABBN_pred', 'CSGN_pred', 'NESN_pred', 'NOVN_pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Yahoo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in stocks_yahoo:\n",
    "    if stock == 'ABBN.VX':\n",
    "        data_yahoo = data.DataReader(stock, 'yahoo', start_date, end_date)\n",
    "        data_yahoo = data_yahoo.drop(columns=['High','Low','Open','Close','Volume'])\n",
    "        data_yahoo = data_yahoo.rename(columns={'Adj Close':stock})\n",
    "    else:\n",
    "        data_yahoo_temp = data.DataReader(stock, 'yahoo', start_date, end_date)\n",
    "        data_yahoo[stock] = data_yahoo_temp['Adj Close']\n",
    "data_yahoo = data_yahoo / data_yahoo.iloc[0] * 100\n",
    "data_yahoo.columns = stocks\n",
    "data_yahoo.to_csv(os.path.join(DATA_CLEAN_DIR, 'yahoo.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Prediction and Yahoo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yahoo = pd.read_csv(os.path.join(DATA_CLEAN_DIR, 'yahoo.csv.gz'), compression='gzip', index_col='Date')\n",
    "cumsum_preds_2004 = pd.read_csv(os.path.join(DATA_CLEAN_DIR, 'cumsum_preds_2004.csv.gz'), compression='gzip',index_col='Unnamed: 0')\n",
    "cumsum_preds_2008 = pd.read_csv(os.path.join(DATA_CLEAN_DIR, 'cumsum_preds_2008.csv.gz'), compression='gzip',index_col='Unnamed: 0')\n",
    "cumsum_preds_2012 = pd.read_csv(os.path.join(DATA_CLEAN_DIR, 'cumsum_preds_2012.csv.gz'), compression='gzip',index_col='Unnamed: 0')\n",
    "cumsum_preds_2016 = pd.read_csv(os.path.join(DATA_CLEAN_DIR, 'cumsum_preds_2016.csv.gz'), compression='gzip',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier(real_data, prediction):\n",
    "    '''\n",
    "    Verifies how much was won or lost during prediction period, by computing the pointwise\n",
    "    product between the prediction and the difference of the real price, then summing up.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    real_data:\n",
    "        Dataframe containing the real prices.\n",
    "    prediction:\n",
    "        Dataframe containing the sign of the prediction.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    result: float\n",
    "        sum of pointwise multiplication\n",
    "    '''\n",
    "    # Index of dataframes to datetime\n",
    "    real_data.index = pd.to_datetime(real_data.index)    \n",
    "    prediction.index = pd.to_datetime(prediction.index)\n",
    "    prediction = prediction.iloc[24::25,:]\n",
    "    prediction.index = prediction.index.date\n",
    "    prediction = np.sign(prediction)\n",
    "    #New dataframe with index of prediction\n",
    "    verification = prediction.join(real_data,how='left')\n",
    "    verification[real_data.columns] = verification[real_data.columns].diff()\n",
    "    verification = verification.dropna()\n",
    "    result = (verification[prediction.columns].values * verification[real_data.columns]).sum().sum()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-82.46556960125604\n",
      "194.2200104688197\n",
      "84.67447512688608\n",
      "297.94742116537395\n"
     ]
    }
   ],
   "source": [
    "print(verifier(data_yahoo, cumsum_preds_2004))\n",
    "print(verifier(data_yahoo, cumsum_preds_2008))\n",
    "print(verifier(data_yahoo, cumsum_preds_2012))\n",
    "print(verifier(data_yahoo, cumsum_preds_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntds_2018",
   "language": "python",
   "name": "ntds_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
